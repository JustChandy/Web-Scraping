# -*- coding: utf-8 -*-
"""6510 Assignment1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fciY84ut60cYwX8DU6bO5jIbSRIZoUA2

## MBAN 6510 Assigment 1 -- Web Scraping

Part 1 : Download HTML for the URL
"""

import requests
import json
from bs4 import BeautifulSoup
import re
import csv
#Store the URL for the review website in a variable
URL = 'https://www.trustpilot.com/review/www.wayfair.ca'

#Get the HTML text for the URL
resp = requests.get(URL)
html_code = resp.text

"""Part 2 : Get the count of reviews"""

#Instantiate html parser object
soup = BeautifulSoup(html_code)

headlines_2 = soup.find_all('h2')
for headline in headlines_2:
    spans = headline.find_all('span')
    for span in spans:
        review_count = int((span.text).replace(',',''))

print("The total number of reviews is :",review_count)

"""Part 3: Get the review information and store in a CSV file"""

#Create a csv file for storing review info
f = open("OnlineReview.csv", 'w')
writer = csv.writer(f,delimiter = ',')
writer.writerow(["company", "datePublished", "ratingValue", "reviewBody"])

#Loop through each webpage containing reviews
num_pages = 27
for i in range(num_pages):
    page = requests.get(URL + '?page=' + str(i+1))
    htmlcode = page.text
    soup = BeautifulSoup(htmlcode)
    reviews = soup.find_all('article', class_='review')
    #Loop through each review in a single page
    for review in reviews:
        #Create bs4 element lists to parse through review body and review published
        #date 
        scripts = review.find_all('script', {"data-initial-state":"review-info"})
        dates = review.find_all('script', {"data-initial-state":"review-dates"})
        for script in scripts:
            #Create dictionary to hold review details inlcuding company, rating 
            #and review body
            review_info = json.loads(script.text)
            for date in dates:
                #Create dictionary to hold review published date
                review_date = json.loads(date.text)
                company = review_info['businessUnitDisplayName']
                pub_date = review_date['publishedDate']
                rating = review_info['stars']
                body = review_info['reviewBody']
                #Write the fields to the csv file
                writer.writerow([company, pub_date, rating, body])

f.close()